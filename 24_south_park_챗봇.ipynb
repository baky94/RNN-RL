{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 마이닝\n",
    "# 사우스파크 챗봇\n",
    "- kaggle 에서 south park 로 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Character</th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Stan</td>\n",
       "      <td>You guys, you guys! Chef is going away. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Kyle</td>\n",
       "      <td>Going away? For how long?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Stan</td>\n",
       "      <td>Forever.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Chef</td>\n",
       "      <td>I'm sorry boys.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Stan</td>\n",
       "      <td>Chef said he's been bored, so he joining a gro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Season Episode Character                                               Line\n",
       "0     10       1      Stan         You guys, you guys! Chef is going away. \\n\n",
       "1     10       1      Kyle                        Going away? For how long?\\n\n",
       "2     10       1      Stan                                         Forever.\\n\n",
       "3     10       1      Chef                                  I'm sorry boys.\\n\n",
       "4     10       1      Stan  Chef said he's been bored, so he joining a gro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df = pd.read_csv('south_park_chatbot/All-seasons.csv')\n",
    "spark_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Character</th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70891</th>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>Stan</td>\n",
       "      <td>I think you're pushing it.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70892</th>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>Randy</td>\n",
       "      <td>How about twenty?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70893</th>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>Stan</td>\n",
       "      <td>That's not disciprine.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70894</th>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>Randy</td>\n",
       "      <td>Right right. Does vodka count?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70895</th>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>Stan</td>\n",
       "      <td>Dad!\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Season Episode Character                              Line\n",
       "70891      9      14      Stan      I think you're pushing it.\\n\n",
       "70892      9      14     Randy               How about twenty?\\n\n",
       "70893      9      14      Stan          That's not disciprine.\\n\n",
       "70894      9      14     Randy  Right right. Does vodka count?\\n\n",
       "70895      9      14      Stan                            Dad!\\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70896 entries, 0 to 70895\n",
      "Data columns (total 4 columns):\n",
      "Season       70896 non-null object\n",
      "Episode      70896 non-null object\n",
      "Character    70896 non-null object\n",
      "Line         70896 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "spark_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10', 'Season', '11', '12', '13', '14', '15', '16', '17', '18',\n",
       "       '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.Season.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Character</th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3471</th>\n",
       "      <td>Season</td>\n",
       "      <td>Episode</td>\n",
       "      <td>Character</td>\n",
       "      <td>Line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6950</th>\n",
       "      <td>Season</td>\n",
       "      <td>Episode</td>\n",
       "      <td>Character</td>\n",
       "      <td>Line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10258</th>\n",
       "      <td>Season</td>\n",
       "      <td>Episode</td>\n",
       "      <td>Character</td>\n",
       "      <td>Line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13516</th>\n",
       "      <td>Season</td>\n",
       "      <td>Episode</td>\n",
       "      <td>Character</td>\n",
       "      <td>Line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16863</th>\n",
       "      <td>Season</td>\n",
       "      <td>Episode</td>\n",
       "      <td>Character</td>\n",
       "      <td>Line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19965</th>\n",
       "      <td>Season</td>\n",
       "      <td>Episode</td>\n",
       "      <td>Character</td>\n",
       "      <td>Line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23086</th>\n",
       "      <td>Season</td>\n",
       "      <td>Episode</td>\n",
       "      <td>Character</td>\n",
       "      <td>Line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25392</th>\n",
       "      <td>Season</td>\n",
       "      <td>Episode</td>\n",
       "      <td>Character</td>\n",
       "      <td>Line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27915</th>\n",
       "      <td>Season</td>\n",
       "      <td>Episode</td>\n",
       "      <td>Character</td>\n",
       "      <td>Line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32086</th>\n",
       "      <td>Season</td>\n",
       "      <td>Episode</td>\n",
       "      <td>Character</td>\n",
       "      <td>Line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38503</th>\n",
       "      <td>Season</td>\n",
       "      <td>Episode</td>\n",
       "      <td>Character</td>\n",
       "      <td>Line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44302</th>\n",
       "      <td>Season</td>\n",
       "      <td>Episode</td>\n",
       "      <td>Character</td>\n",
       "      <td>Line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49983</th>\n",
       "      <td>Season</td>\n",
       "      <td>Episode</td>\n",
       "      <td>Character</td>\n",
       "      <td>Line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54398</th>\n",
       "      <td>Season</td>\n",
       "      <td>Episode</td>\n",
       "      <td>Character</td>\n",
       "      <td>Line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59530</th>\n",
       "      <td>Season</td>\n",
       "      <td>Episode</td>\n",
       "      <td>Character</td>\n",
       "      <td>Line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63767</th>\n",
       "      <td>Season</td>\n",
       "      <td>Episode</td>\n",
       "      <td>Character</td>\n",
       "      <td>Line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67369</th>\n",
       "      <td>Season</td>\n",
       "      <td>Episode</td>\n",
       "      <td>Character</td>\n",
       "      <td>Line</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Season  Episode  Character  Line\n",
       "3471   Season  Episode  Character  Line\n",
       "6950   Season  Episode  Character  Line\n",
       "10258  Season  Episode  Character  Line\n",
       "13516  Season  Episode  Character  Line\n",
       "16863  Season  Episode  Character  Line\n",
       "19965  Season  Episode  Character  Line\n",
       "23086  Season  Episode  Character  Line\n",
       "25392  Season  Episode  Character  Line\n",
       "27915  Season  Episode  Character  Line\n",
       "32086  Season  Episode  Character  Line\n",
       "38503  Season  Episode  Character  Line\n",
       "44302  Season  Episode  Character  Line\n",
       "49983  Season  Episode  Character  Line\n",
       "54398  Season  Episode  Character  Line\n",
       "59530  Season  Episode  Character  Line\n",
       "63767  Season  Episode  Character  Line\n",
       "67369  Season  Episode  Character  Line"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df[spark_df.Season == 'Season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cartman         9774\n",
       "Stan            7680\n",
       "Kyle            7099\n",
       "Butters         2602\n",
       "Randy           2467\n",
       "Mr. Garrison    1002\n",
       "Chef             917\n",
       "Kenny            881\n",
       "Sharon           862\n",
       "Mr. Mackey       633\n",
       "Name: Character, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.Character.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1585"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.Line.apply(len).max() # 3(min) ~ 1585(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, first of all, I am NOT Aquaman, I am a recovering... gay fish. Yes, I have met Aquaman. I have hung out with Aquaman. But the only thing I have in common with Aquaman anymore is my love for the sea.  Now!  There have been malicious rumors, started at this elementary school, that my beautiful fiancée is a hobbit. That is not funny, and it is not true.  Alright?! Yes, Kim is heavier than most of her pictures show her to be. Yes, she gets her hair lasered off her body. Yes, she has a friend named Gandalf who happens to be a wizard.  I'm sorry, excuse me a minute.  Bitch, how are you not a hobbit again? Yeah. Yeah yeah yeah right. Rightrightrightrightright, yeah. Okay. Yep. Yep. Let me get- okay. Yep, I got it. Okay, love you too.  Okay, if my fiancée Kim… is… a hobbit, then how come… it uh how c- then, okay, if she's a hobbit, then how come she don't live in a hole in the ground? BOOOOOOM! All y'all just got lit up, cuz! She don't live in no hole in the ground, she lives in a big-ass mansion, with me, in her room, that is slightly below ground! So, you can… She, she is sexy, and womanly, and she smokes a pipe. She can blow them rings that go up over her head, and… Hold up. Bitch, you not a hobbit, right? ... No, I know, you just, you smoke that long pipe sometimes when you sit by the fire... Oh it's a- Oh, okay. Got it, got it- What do you call it? Yep. Yep, got it. Okay. Yep, love you too.  That is not a hobbit pipe, for your information! It is a personal oral humidifier to keep all the wrinkles around her mouth from showin'. So haha, all you haters, HA!\n",
      "\n",
      "Oh\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(spark_df.iloc[spark_df.Line.apply(len).idxmax(),3])\n",
    "print(spark_df.iloc[spark_df.Line.apply(len).idxmin(),3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    '''Clean text by removing unnecessary characters and altering the format of words.'''\n",
    "\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r\"\\n\", \"\",  text)\n",
    "    text = re.sub(r\"[-()]\", \"\", text)\n",
    "    text = re.sub(r\"\\.\", \" .\", text)\n",
    "    text = re.sub(r\"\\!\", \" !\", text)\n",
    "    text = re.sub(r\"\\?\", \" ?\", text)\n",
    "    text = re.sub(r\"\\,\", \" ,\", text)\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"that is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"n'\", \"ng\", text)\n",
    "    text = re.sub(r\"ohh\", \"oh\", text)\n",
    "    text = re.sub(r\"ohhh\", \"oh\", text)\n",
    "    text = re.sub(r\"ohhhh\", \"oh\", text)\n",
    "    text = re.sub(r\"ohhhhh\", \"oh\", text)\n",
    "    text = re.sub(r\"ohhhhhh\", \"oh\", text)\n",
    "    text = re.sub(r\"ahh\", \"ah\", text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "text = []\n",
    "\n",
    "for line in spark_df.Line:\n",
    "    text.append(clean_text(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70896"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70896"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = [len(s.split()) for s in text]\n",
    "len(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63991"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_line_length = 30\n",
    "\n",
    "short_text = [s for s in text if len(s.split())<=max_line_length]\n",
    "len(short_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24075"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {}\n",
    "for s in short_text:\n",
    "    for w in s.split():\n",
    "        if w in vocab: vocab[w] += 1\n",
    "        else: vocab[w] = 1\n",
    "        \n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8333"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab2 = vocab.copy()\n",
    "for k,v in vocab2.items():\n",
    "    if v<3: del vocab[k]\n",
    "        \n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you : 19705\n",
      "guys : 1503\n",
      ", : 42194\n",
      "! : 34689\n",
      "chef : 354\n",
      "is : 14211\n",
      "going : 1319\n",
      "away : 412\n",
      ". : 57630\n",
      "? : 19930\n",
      "for : 3364\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "for k in vocab:\n",
    "    print(k+' : '+str(vocab[k]))\n",
    "    if n>=10: break\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8333"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab2int = {}\n",
    "for i, (k,v) in enumerate(vocab.items()):\n",
    "    vocab2int[k] = i\n",
    "    \n",
    "len(vocab2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8337"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes = ['<PAD>','<EOS>','<UNK>','<GO>']\n",
    "vocab_len = len(vocab2int)\n",
    "for i in range(4):\n",
    "    vocab2int[codes[i]] = vocab_len + i\n",
    "    \n",
    "len(vocab2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8337"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int2vocab = {v:k for k,v in vocab2int.items()}\n",
    "len(int2vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you guys , you guys ! chef is going away . ',\n",
       " 'going away ? for how long ?',\n",
       " 'forever .',\n",
       " 'i am sorry boys .',\n",
       " 'chef said he is been bored , so he joining a group called the super adventure club . ']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_text = short_text[:-1]\n",
    "target_text = short_text[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab2int)\n",
    "\n",
    "source_vector = []\n",
    "for s in source_text:\n",
    "    l = []\n",
    "    for w in s.split():\n",
    "        if w in vocab2int: l.append(vocab2int[w])\n",
    "        else: l.append(vocab_len-2) # '<UNK>'\n",
    "    source_vector.append(l)\n",
    "    \n",
    "target_vector = []\n",
    "for s in target_text:\n",
    "    l = []\n",
    "    for w in s.split():\n",
    "        if w in vocab2int: l.append(vocab2int[w])\n",
    "        else: l.append(vocab_len-2) # '<UNK>'\n",
    "    target_vector.append(l+[vocab_len-3]) # <'EOS'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63990, 63990)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source_vector), len(target_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([6, 7, 9, 10, 11, 12, 9], [6, 7, 9, 10, 11, 12, 9, 8334])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_vector[1], target_vector[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 정리\n",
    "- source_vector : 입력 문장의 시퀀스, 63990개 (한 시퀀스의 길이는 1 ~ 30)\n",
    "- target_vector : 출력 문장의 시퀀스, 63990개, 끝에 ```<EOS>``` 추가, (한 시퀀스의 길이는 2 ~ 31)\n",
    "- vocab2int : 단어-인덱스 사전, 8337개 단어, 끝에 ```<PAD>,<EOS>,<UNK>,<GO>```\n",
    "- int2vocab : 인덱스-단어 사전, 8337개 단어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 케라스 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(8337, 8, input_length=None)) # 단어갯수, 변환차원, 시퀀스길이\n",
    "# keras.preprocessing.sequence.pad_sequences() 이용해 시퀀스 길이를 제한할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Embedding in module keras.layers.embeddings:\n",
      "\n",
      "class Embedding(keras.engine.base_layer.Layer)\n",
      " |  Turns positive integers (indexes) into dense vectors of fixed size.\n",
      " |  eg. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]\n",
      " |  \n",
      " |  This layer can only be used as the first layer in a model.\n",
      " |  \n",
      " |  # Example\n",
      " |  \n",
      " |  ```python\n",
      " |    model = Sequential()\n",
      " |    model.add(Embedding(1000, 64, input_length=10))\n",
      " |    # the model will take as input an integer matrix of size (batch, input_length).\n",
      " |    # the largest integer (i.e. word index) in the input should be\n",
      " |    # no larger than 999 (vocabulary size).\n",
      " |    # now model.output_shape == (None, 10, 64), where None is the batch dimension.\n",
      " |  \n",
      " |    input_array = np.random.randint(1000, size=(32, 10))\n",
      " |  \n",
      " |    model.compile('rmsprop', 'mse')\n",
      " |    output_array = model.predict(input_array)\n",
      " |    assert output_array.shape == (32, 10, 64)\n",
      " |  ```\n",
      " |  \n",
      " |  # Arguments\n",
      " |      input_dim: int > 0. Size of the vocabulary,\n",
      " |          i.e. maximum integer index + 1.\n",
      " |      output_dim: int >= 0. Dimension of the dense embedding.\n",
      " |      embeddings_initializer: Initializer for the `embeddings` matrix\n",
      " |          (see [initializers](../initializers.md)).\n",
      " |      embeddings_regularizer: Regularizer function applied to\n",
      " |          the `embeddings` matrix\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      embeddings_constraint: Constraint function applied to\n",
      " |          the `embeddings` matrix\n",
      " |          (see [constraints](../constraints.md)).\n",
      " |      mask_zero: Whether or not the input value 0 is a special \"padding\"\n",
      " |          value that should be masked out.\n",
      " |          This is useful when using [recurrent layers](recurrent.md)\n",
      " |          which may take variable length input.\n",
      " |          If this is `True` then all subsequent layers\n",
      " |          in the model need to support masking or an exception will be raised.\n",
      " |          If mask_zero is set to True, as a consequence, index 0 cannot be\n",
      " |          used in the vocabulary (input_dim should equal size of\n",
      " |          vocabulary + 1).\n",
      " |      input_length: Length of input sequences, when it is constant.\n",
      " |          This argument is required if you are going to connect\n",
      " |          `Flatten` then `Dense` layers upstream\n",
      " |          (without it, the shape of the dense outputs cannot be computed).\n",
      " |  \n",
      " |  # Input shape\n",
      " |      2D tensor with shape: `(batch_size, sequence_length)`.\n",
      " |  \n",
      " |  # Output shape\n",
      " |      3D tensor with shape: `(batch_size, sequence_length, output_dim)`.\n",
      " |  \n",
      " |  # References\n",
      " |      - [A Theoretically Grounded Application of Dropout in\n",
      " |         Recurrent Neural Networks](http://arxiv.org/abs/1512.05287)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Embedding\n",
      " |      keras.engine.base_layer.Layer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the layer weights.\n",
      " |      \n",
      " |      Must be implemented on all layers that have weights.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Keras tensor (future input to layer)\n",
      " |              or list/tuple of Keras tensors to reference\n",
      " |              for weight shape computations.\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      # Returns\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      Assumes that the layer will be built\n",
      " |      to match that input shape provided.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, **kwargs)\n",
      " |      Wrapper around self.call(), for handling internal references.\n",
      " |      \n",
      " |      If a Keras tensor is passed:\n",
      " |          - We call self._add_inbound_node().\n",
      " |          - If necessary, we `build` the layer to match\n",
      " |              the _keras_shape of the input(s).\n",
      " |          - We update the _keras_shape of every input tensor with\n",
      " |              its new shape (obtained via self.compute_output_shape).\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |          - We update the _keras_history of the output tensor(s)\n",
      " |              with the current layer.\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Can be a tensor or list/tuple of tensors.\n",
      " |          **kwargs: Additional keyword arguments to be passed to `call()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output of the layer's `call` method.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case the layer is missing shape information\n",
      " |              for its `build` call.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Adds losses to the layer.\n",
      " |      \n",
      " |      The loss may potentially be conditional on some inputs tensors,\n",
      " |      for instance activity losses are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          losses: loss tensor or list of loss tensors\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the losses as conditional on these inputs.\n",
      " |              If None is passed, the loss is assumed unconditional\n",
      " |              (e.g. L2 weight regularization, which only depends\n",
      " |              on the layer's weights variables, not on any inputs tensors).\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Adds updates to the layer.\n",
      " |      \n",
      " |      The updates may potentially be conditional on some inputs tensors,\n",
      " |      for instance batch norm updates are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          updates: update op or list of update ops\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the updates as conditional on these inputs.\n",
      " |              If None is passed, the updates are assumed unconditional.\n",
      " |  \n",
      " |  add_weight(self, name, shape, dtype=None, initializer=None, regularizer=None, trainable=True, constraint=None)\n",
      " |      Adds a weight variable to the layer.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, the name for the weight variable.\n",
      " |          shape: The shape tuple of the weight.\n",
      " |          dtype: The dtype of the weight.\n",
      " |          initializer: An Initializer instance (callable).\n",
      " |          regularizer: An optional Regularizer instance.\n",
      " |          trainable: A boolean, whether the weight should\n",
      " |              be trained via backprop or not (assuming\n",
      " |              that the layer itself is also trainable).\n",
      " |          constraint: An optional Constraint instance.\n",
      " |      \n",
      " |      # Returns\n",
      " |          The created weight variable.\n",
      " |  \n",
      " |  assert_input_compatibility(self, inputs)\n",
      " |      Checks compatibility between the layer and provided inputs.\n",
      " |      \n",
      " |      This checks that the tensor(s) `input`\n",
      " |      verify the input assumptions of the layer\n",
      " |      (if any). If not, exceptions are raised.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case of mismatch between\n",
      " |              the provided inputs and the expectations of the layer.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Counts the total number of scalars composing the weights.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An integer count.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the layer isn't yet built\n",
      " |              (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  built\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input shape tuple\n",
      " |          (or list of input shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  losses\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output tensor or list of output tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one inbound node,\n",
      " |      or if all inbound nodes have the same output shape.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output shape tuple\n",
      " |          (or list of input shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  weights\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
